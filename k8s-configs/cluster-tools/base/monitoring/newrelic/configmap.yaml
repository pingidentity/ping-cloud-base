---
# Source: nri-bundle/charts/nri-kube-events/templates/configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    nri-bundle.version: 5.0.4
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-kube-events
    app.kubernetes.io/version: 1.8.0
    helm.sh/chart: nri-kube-events-2.2.4
  name: nri-bundle-nri-kube-events-config
  namespace: newrelic
data:
  # In case of making any changes to this file it should be added to corresponding patch listed in these files:
  # - ping-cloud-base/code-gen/templates/common/base/cluster-tools/monitoring/kustomization.yaml
  # - ping-cloud-base/dev-cluster-state/cluster-tools/kustomization.yaml
  config.yaml: |-
    sinks:
    - name: newRelicInfra
      config:
        agentEndpoint: http://localhost:8001/v1/data
        clusterName: k8s-cluster-name
        agentHTTPTimeout: 30s

---
# Source: nri-bundle/charts/nri-prometheus/templates/configmap.yaml

kind: ConfigMap
metadata:
  name: nri-bundle-nri-prometheus-config
  namespace: newrelic
  labels:
    app.kubernetes.io/name: nri-prometheus
    helm.sh/chart: nri-prometheus-1.10.0
    app.kubernetes.io/version: "2.9.0"
apiVersion: v1
data:
  # In case of making any changes to this file it should be added to corresponding patch listed in these files:
  # - ping-cloud-base/code-gen/templates/common/base/cluster-tools/monitoring/kustomization.yaml
  # - ping-cloud-base/dev-cluster-state/cluster-tools/kustomization.yaml
  config.yaml: |
    cluster_name: k8s-cluster-name
    audit: false
    insecure_skip_verify: true
    require_scrape_enabled_label_for_nodes: true
    scrape_enabled_label: prometheus.io/scrape
    scrape_endpoints: false
    scrape_services: true
    transformations:
    - description: Low data mode defaults
      ignore_metrics:
      - prefixes:
        - kube_
        - container_
        - machine_
        - cadvisor_
    verbose: false

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/controlplane/agent-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  namespace: newrelic
  labels:
    nri-bundle.version: 5.0.4
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-agent-controlplane
data:
  # In case of making any changes to this file it should be added to corresponding patch listed in these files:
  # - ping-cloud-base/code-gen/templates/common/base/cluster-tools/monitoring/kustomization.yaml
  # - ping-cloud-base/dev-cluster-state/cluster-tools/kustomization.yaml
  newrelic-infra.yml: |-
    # This is the configuration file for the infrastructure agent. See:
    # https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/
    custom_attributes:
      clusterName: k8s-cluster-name
    # Report metric data about all the operating system's processes (PDO-4178)
    enable_process_metrics: true
    http_server_enabled: true
    http_server_port: 8001
    is_forward_only: true

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/controlplane/scraper-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    nri-bundle.version: 5.0.4
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-controlplane
  namespace: newrelic
data:
  nri-kubernetes.yml: |-
    interval: 15s # Default value is 15s
    controlPlane:
      retries: 3
      timeout: 10s
      enabled: true
      etcd:
        autodiscover:
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:4001
          - url: http://localhost:2381
          matchNode: true
          namespace: kube-system
          selector: tier=control-plane,component=etcd
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:4001
          matchNode: true
          namespace: kube-system
          selector: k8s-app=etcd-manager-main
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:4001
          matchNode: true
          namespace: kube-system
          selector: k8s-app=etcd
        enabled: true
      scheduler:
        autodiscover:
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10259
          matchNode: true
          namespace: kube-system
          selector: tier=control-plane,component=kube-scheduler
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10259
          matchNode: true
          namespace: kube-system
          selector: k8s-app=kube-scheduler
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10259
          matchNode: true
          namespace: kube-system
          selector: app=openshift-kube-scheduler,scheduler=true
        enabled: true
      controllerManager:
        autodiscover:
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10257
          matchNode: true
          namespace: kube-system
          selector: tier=control-plane,component=kube-controller-manager
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10257
          matchNode: true
          namespace: kube-system
          selector: k8s-app=kube-controller-manager
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10257
          matchNode: true
          namespace: kube-system
          selector: app=kube-controller-manager,kube-controller-manager=true
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10257
          matchNode: true
          namespace: kube-system
          selector: app=controller-manager,controller-manager=true
        enabled: true
      apiServer:
        autodiscover:
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:8443
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:6443
          - url: http://localhost:8080
          matchNode: true
          namespace: kube-system
          selector: tier=control-plane,component=kube-apiserver
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:8443
          - url: http://localhost:8080
          matchNode: true
          namespace: kube-system
          selector: k8s-app=kube-apiserver
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:8443
          matchNode: true
          namespace: kube-system
          selector: app=openshift-kube-apiserver,apiserver=true
        enabled: true

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/ksm/agent-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  namespace: newrelic
  labels:
    nri-bundle.version: 5.0.4
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-agent-ksm
data:
  # In case of making any changes to this file it should be added to corresponding patch listed in these files:
  # - ping-cloud-base/code-gen/templates/common/base/cluster-tools/monitoring/kustomization.yaml
  # - ping-cloud-base/dev-cluster-state/cluster-tools/kustomization.yaml
  newrelic-infra.yml: |-
    # This is the configuration file for the infrastructure agent. See:
    # https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/
    custom_attributes:
      clusterName: k8s-cluster-name
    http_server_enabled: true
    http_server_port: 8002
    is_forward_only: true

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/ksm/scraper-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    nri-bundle.version: 5.0.4
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.6.0
    helm.sh/chart: newrelic-infrastructure-3.12.0
  name: nri-bundle-nrk8s-ksm
  namespace: newrelic
data:
  nri-kubernetes.yml: |-
    interval: 15s # Default value is 15s
    ksm:
      enabled: true
      retries: 3
      scheme: http
      selector: app.kubernetes.io/name=kube-state-metrics
      timeout: 10s

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/kubelet/agent-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  namespace: newrelic
  labels:
    nri-bundle.version: 5.0.4
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-agent-kubelet
data:
  # In case of making any changes to this file it should be added to corresponding patch listed in these files:
  # - ping-cloud-base/code-gen/templates/common/base/cluster-tools/monitoring/kustomization.yaml
  # - ping-cloud-base/dev-cluster-state/cluster-tools/kustomization.yaml
  newrelic-infra.yml: |-
    # This is the configuration file for the infrastructure agent. See:
    # https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/
    custom_attributes:
      clusterName: k8s-cluster-name
    features:
      docker_enabled: false
    http_server_enabled: true
    http_server_port: 8003

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/kubelet/integrations-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  namespace: newrelic
  labels:
    nri-bundle.version: 5.0.4
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-integrations-cfg
data:
  # This ConfigMap holds config files for integrations. They should have the following format:
  #redis-config.yml: |
  #  # Run auto discovery to find pods with label "app=redis"
  #  discovery:
  #    command:
  #      # Run discovery for Kubernetes. Use the following optional arguments:
  #      # --namespaces: Comma separated list of namespaces to discover pods on
  #      # --tls: Use secure (TLS) connection
  #      # --port: Port used to connect to the kubelet. Default is 10255
  #      exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls
  #      match:
  #        label.app: redis
  #  integrations:
  #    - name: nri-redis
  #      env:
  #        # using the discovered IP as the hostname address
  #        HOSTNAME: ${discovery.ip}
  #        PORT: 6379
  #        KEYS: '{"0":["<KEY_1>"],"1":["<KEY_2>"]}'
  #        REMOTE_MONITORING: true
  #      labels:
  #        env: production
  
  pixie-health-check.yaml: |
    ---
    # This Flex config performs periodic checks of the Pixie
    # /healthz and /statusz endpoints exposed by the Pixie Cloud Connector.
    # A status for each endpoint is sent to New Relic in a pixieHealthCheck event.
    #
    # If Pixie is not installed in the cluster, no events will be generated.
    # This can also be disabled with enablePixieHealthCheck: false in the values.yaml file.
    discovery:
      command:
        exec: /var/db/newrelic-infra/nri-discovery-kubernetes --tls --port 10250
        match:
          label.name: vizier-cloud-connector
    integrations:
      - name: nri-flex
        interval: 60s
        config:
          name: pixie-health-check
          apis:
            - event_type: pixieHealth
              commands:
                - run: curl --insecure -s https://${discovery.ip}:50800/healthz | xargs | awk '{print "cloud_connector_health:"$1}'
                  split_by: ":"
              merge: pixieHealthCheck
            - event_type: pixieStatus
              commands:
                - run: curl --insecure -s https://${discovery.ip}:50800/statusz | awk '{if($1 == ""){ print "cloud_connector_status:OK" } else { print "cloud_connector_status:"$1 }}'
                  split_by: ":"
              merge: pixieHealthCheck

---
# New Relic Pingmetadata Integration

apiVersion: v1
kind: ConfigMap
metadata:
  name: pingmetadata
  namespace: newrelic
data:
  pingmetadata.yaml: |
    ---
    integrations:
      - name: nri-flex
        interval: 2m
        config:
          name: pingmetadata
          apis:
            - event_type: pingmetaDataOutputSample
              url: http://metadata.${PING_CLOUD_NAMESPACE}:5000
              jq: ".version"

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/kubelet/scraper-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    nri-bundle.version: 5.0.4
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-kubelet
  namespace: newrelic
data:
  nri-kubernetes.yml: |
    interval: 15s # Default value is 15s
    kubelet:
      enabled: true
      retries: 3
      timeout: 10s

---
# Script to provision NewRelic secrets

apiVersion: v1
kind: ConfigMap
metadata:
  name: copy-secret
  namespace: newrelic
data:
  copy-secret.sh: |-
    #!/bin/sh

    cd /tmp

    kubectl get secret ${SECRET_NAME} \
        -n ${SECRET_NAMESPACE} \
        -o jsonpath='{.data.NEW_RELIC_LICENSE_KEY}' |
    base64 -d > NEW_RELIC_LICENSE_KEY

    kubectl create secret generic ${SECRET_NAME} \
        -n ${CURRENT_NAMESPACE} \
        --from-file=NEW_RELIC_LICENSE_KEY

    rm -f NEW_RELIC_LICENSE_KEY

---
# Source: nri-bundle/charts/nri-kube-events/templates/agent-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    nri-bundle.version: 5.0.4
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-kube-events
    app.kubernetes.io/version: 1.8.0
    helm.sh/chart: nri-kube-events-2.2.4
  name: nri-bundle-nri-kube-events-agent-config
  namespace: newrelic
data:
  newrelic-infra.yml: |
    is_forward_only: true
    http_server_enabled: true
    http_server_port: 8001