# FIXME: Due to the following bug in kustomize, we're having to copy the nginx
# yaml files for the private nginx controller and corresponding service instead
# of using their remote github URL:
#
# https://github.com/kubernetes-sigs/kustomize/issues/1248
#
# The bug is that inheriting from a common base in two or more peer directories
# results in the following error for common "vars" defined in the base. For
# example, if the base kustomization has a var named "POD_NAME", then two
# peer overlays prod and staging will work independently. But when built
# together will result in this error:
#
# Error: accumulating resources: recursed merging from path 'staging': var
# 'POD_NAME' already encountered
#
# There is a PR for the defect, but it hasn't been merged yet. When the latest
# kustomize is released, we should get rid of this and do the kustomization
# the same way as the public ingress is done, i.e. using the remote URL from
# the nginx ingress repo.

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-ingress-controller
spec:
  replicas: 1
  template:
    metadata:
      annotations:
        prometheus.io/port: "10254"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: nginx-ingress-serviceaccount
      containers:
        - name: nginx-ingress-controller
          image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.25.0
          args:
            - /nginx-ingress-controller
            - --configmap=$(POD_NAMESPACE)/$(NGINX_CONFIGMAP_NAME)
            - --tcp-services-configmap=$(POD_NAMESPACE)/$(TCP_CONFIGMAP_NAME)
            - --udp-services-configmap=$(POD_NAMESPACE)/$(UDP_CONFIGMAP_NAME)
            - --publish-service=$(POD_NAMESPACE)/$(SERVICE_NAME)
            - --annotations-prefix=nginx.ingress.kubernetes.io
            - --ingress-class=nginx-private
          securityContext:
            allowPrivilegeEscalation: true
            capabilities:
              drop:
                - ALL
              add:
                - NET_BIND_SERVICE
            # www-data -> 33
            runAsUser: 33
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - name: http
              containerPort: 80
            - name: https
              containerPort: 443
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 10
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 10